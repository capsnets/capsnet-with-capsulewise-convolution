{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing custom CapsNet trained on padded and translated MNIST train set on affNIST test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Conv2D, Activation, Dense, Dropout, Lambda\n",
    "from keras.layers import BatchNormalization, MaxPooling2D, Flatten, Conv1D\n",
    "from convcaps.capslayers import ConvertToCaps, Conv2DCaps, FlattenCaps\n",
    "from convcaps.capslayers import DenseCaps, CapsToScalars\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "from scipy.io import matlab\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train set generated in generate_datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 40, 40\n",
    "num_classes = 10\n",
    "\n",
    "x_train = np.load('generateddatasets/x_train_only_translation.npy').astype(np.float32)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_train /= 255.0\n",
    "\n",
    "y_train = np.load('generateddatasets/y_train_only_translation.npy')\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 18, 16)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 18, 18, 16)        64        \n",
      "_________________________________________________________________\n",
      "convert_to_caps_1 (ConvertTo (None, 18, 18, 16, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_caps_1 (Conv2DCaps)   (None, 8, 8, 6, 4)        3456      \n",
      "_________________________________________________________________\n",
      "conv2d_caps_2 (Conv2DCaps)   (None, 6, 6, 5, 5)        5400      \n",
      "_________________________________________________________________\n",
      "conv2d_caps_3 (Conv2DCaps)   (None, 4, 4, 4, 6)        5400      \n",
      "_________________________________________________________________\n",
      "conv2d_caps_4 (Conv2DCaps)   (None, 2, 2, 3, 7)        4536      \n",
      "_________________________________________________________________\n",
      "flatten_caps_1 (FlattenCaps) (None, 12, 7)             0         \n",
      "_________________________________________________________________\n",
      "dense_caps_1 (DenseCaps)     (None, 10, 8)             6720      \n",
      "_________________________________________________________________\n",
      "caps_to_scalars_1 (CapsToSca (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,992\n",
      "Trainable params: 25,960\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l2 = regularizers.l2(l=0.001)\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "l = inp\n",
    "\n",
    "l = Conv2D(16, (5, 5), strides=(2, 2), activation='relu', kernel_regularizer=l2)(l)  # common conv layer\n",
    "l = BatchNormalization()(l)\n",
    "l = ConvertToCaps()(l)\n",
    "l = Conv2DCaps(6, 4, (3, 3), (2, 2), r_num=1, b_alphas=[1, 1, 1], kernel_regularizer=l2)(l)\n",
    "l = Conv2DCaps(5, 5, (3, 3), (1, 1), r_num=1, b_alphas=[1, 1, 1], kernel_regularizer=l2)(l)\n",
    "l = Conv2DCaps(4, 6, (3, 3), (1, 1), r_num=1, b_alphas=[1, 1, 1], kernel_regularizer=l2)(l)\n",
    "l = Conv2DCaps(3, 7, (3, 3), (1, 1), r_num=1, b_alphas=[1, 1, 1], kernel_regularizer=l2)(l)\n",
    "\n",
    "l = FlattenCaps()(l)  # transform to a dense caps layer\n",
    "l = DenseCaps(10, 8, r_num=3, b_alphas=[1, 8, 8], kernel_regularizer=l2)(l)\n",
    "l = CapsToScalars()(l)\n",
    "\n",
    "model = Model(inputs=inp, outputs=l, name='40x40_input_capsnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caps_objective(y_true, y_pred):\n",
    "    return K.sum(y_true * K.clip(0.8 - y_pred, 0, 1) ** 2 + 0.5 * (1 - y_true) * K.clip(y_pred - 0.3, 0, 1) ** 2)\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=caps_objective,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_path = os.path.join('weights', model.name)\n",
    "\n",
    "if not os.path.exists(w_path):\n",
    "    os.makedirs(w_path)\n",
    "    \n",
    "f_name = os.path.join(w_path, 'weights.{epoch:02d}.hdf5')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('weights/40x40_input_capsnet/weights.03.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 436800 samples, validate on 43200 samples\n",
      "Epoch 1/4\n",
      "436800/436800 [==============================] - 910s - loss: 0.7221 - acc: 0.9490 - val_loss: 0.3835 - val_acc: 0.9764\n",
      "Epoch 2/4\n",
      "436800/436800 [==============================] - 925s - loss: 0.3840 - acc: 0.9749 - val_loss: 0.3295 - val_acc: 0.9796\n",
      "Epoch 3/4\n",
      "436800/436800 [==============================] - 743s - loss: 0.3569 - acc: 0.9763 - val_loss: 0.3361 - val_acc: 0.9794\n",
      "Epoch 4/4\n",
      "436800/436800 [==============================] - 528s - loss: 0.3426 - acc: 0.9772 - val_loss: 0.3072 - val_acc: 0.9796\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 4\n",
    "\n",
    "h = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=num_epochs, initial_epoch=0,\n",
    "          verbose=1, validation_split=0.09,\n",
    "          callbacks=[ModelCheckpoint(f_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on affNIST test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319936/320000 [============================>.] - ETA: 0s\n",
      "Test score:  3.78991742519\n",
      "Test accuracy:  0.704396875\n"
     ]
    }
   ],
   "source": [
    "f = matlab.loadmat('affnist/test.mat')\n",
    "\n",
    "x_test = f['affNISTdata'][0, 0][2].transpose().astype(np.float32)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_test /= 255\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "y_test = f['affNISTdata'][0, 0][4].transpose()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('')\n",
    "print('Test score: ', score[0])\n",
    "print('Test accuracy: ', score[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
